# wAlnut

*Think using a priority checklist of mental models*  

#### Table of Contents
- **[History of this Repository](#history-of-this-repository)**
- **[Y & Goals](#y--goals)**

## History of this Repository

In 2011 `Q 0` watched [Jeff Hawkin's talk](https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing) on artificial general intelligence(AGI) and `Q 1` became obsessed with building AGI 2 help humanity. `Q 2` taught `Q 1` how 2 code & built an OO Java implementation of [Numenta's cortical learning algorithm(CLA) v2](https://github.com/WalnutiQ/wAlnut/tree/MARK_II). After running unsuccessful vision experiments using the Cortical Learning Algorithm(CLA v2) `Q 3` began 2 think there must b 1+ better approaches 2 building AGI. `Q 4` found 1 better approach in Dileep George's [PhD thesis](https://github.com/WalnutiQ/papers/blob/master/Dileep_George_PGM/HowTheBrainMightWork.pdf) & the project changed in2 an [OO Python implementation of Dileep's PhD thesis](https://github.com/WalnutiQ/wAlnut/tree/MARK_III). While researching other approaches 2 AGI `Q 5` found [Elon Musk's ideas on AGI](https://youtu.be/h0962biiZa4)
& read [Superintelligence by Nick Bostrom](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/1501227742) with `Q 6`'s notes [here](https://github.com/WalnutiQ/wAlnut/issues/345) & realized `Q 0` made false assumptions about building AGI 2 help humanity in the 1st place. The goal changed 2 researching how 2 increase human 
intelligence faster than code based intelligence. The idea `Q 7` has reached is since AGI will not b limited by slow biological processes, it isn't possible 4 human intelligence to increase faster than code based intelligence in the long-term. Now `Q 194.33.14.5.2` is using 91 mental models 2 brainstorm alternative solutions 2 the AGI problem. If ur interested in thinking about this together e-mail `Q` ur CV @ emn1over12@gmail.com :)

~ `Q 229.35`

## Y & Goals
Between 2011 to 2016 I was so focused on how to build AGI it was so easy for me to have confirmation bias toward only the potential positive effects of building AGI while a part of me avoided the question:
  
`Q0: How do you control something that is smarter than all of humanity combined?`

The answer is you can not. I now believe AGI should not be built privately or publicly and instead one possible solution is to increase human intelligence with a privately built neural lace like [Neuralink](https://neuralink.com/) which you can read about [here](http://waitbutwhy.com/2017/04/neuralink.html). 

Today, many groups r trying to build AGI to help humanity. However, I believe AGI should not be built because:

1. Humans r the dominant species on Earth because of our intelligence.
2. If we make another species (code based AGI) smarter than us then there is no way for us to control it 
   because you can't control something that is more intelligent than all of humanity combined.
3. There is a very high chance that it will use humans for purposes we do not want. Just look at how we treat species 
   that r less intelligent than us.
4. We cannot stop the humans that r researching AGI so now the question is:

`Q1: How do we solve the AGI control problem?`  
Using a checklist of 101 mental models I've brainstormed the following possible answers:

1. Increase human intelligence faster than AGI. 
   - `Problem:` AGI will not be limited by slow biological processes so I don't think this is possible in the long-term. 
2. Give everyone who wants one a neural lace. 
   - `Problem:` Not sure if this is healthy for any human as it might cause insanity since we don't fully understand the brain yet. 
3. AGI development regulation.
   - `Problem:` I don't think this is scalable since it will not be possible to monitor every AGI developer like it is possible to monitor every nuclear bomb developer. And as knowledge of how to build AGI increases more people with self-serving motives can create a AGI without understanding the consequences.
4. Figure out how to backwards time travel ethically.
   - `Problem:` I don't know anyone that will take me seriously yet :) 
5. Something I haven't or can't even imagine. 

Using Occam's razor 2 is the possible answer with the least number of assumptions so now the questions becomes `Q2` & `Q3`:
  
`Q2: How do you create a safe neural lace for anyone who wants one?`.

1. First use it to help the mentally disabled. 
2. I'm not sure giving a neural lace to a mentally normal person is healthy as our lack of full understanding of the brain may cause unexpected insanity in the wearer.
3. Privately research the best cyber security to be used for people with neural lace. 

`Q3: How do you fully understand the human brain without building an improved version of it in code?`

1. Non-Answer: In all other cases to truly understand an thing just rebuild a better version of it. However, in this case that means building an AGI. 

~ `Q 142.29 Liu`
