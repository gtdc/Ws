# W

*Think using a priority checklist of mental models*  

#### Table of Contents
- **[History of this Repository](#history-of-this-repository)**
- **[Y & Goals](#y--goals)**

## History of this Repository

In 2011 `Q 0` watched [Jeff Hawkin's talk](https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing) on artificial general intelligence(AGI) and `Q 1` became obsessed with building AGI 2 help humanity. `Q 2` taught `Q 1` how 2 code & built an OO Java implementation of [Numenta's cortical learning algorithm(CLA) v2](https://github.com/WalnutiQ/wAlnut/tree/MARK_II). After running unsuccessful vision experiments using the Cortical Learning Algorithm(CLA v2) `Q 3` began 2 think there must b 1+ better approaches 2 building AGI. `Q 4` found 1 better approach in Dileep George's [PhD thesis](https://github.com/WalnutiQ/papers/blob/master/Dileep_George_PGM/HowTheBrainMightWork.pdf) & the project changed in2 an [OO Python implementation of Dileep's PhD thesis](https://github.com/WalnutiQ/wAlnut/tree/MARK_III). While researching other approaches 2 AGI `Q 5` found [Elon Musk's ideas on AGI](https://youtu.be/h0962biiZa4)
& read [Superintelligence by Nick Bostrom](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/1501227742) with `Q 6`'s notes [here](https://github.com/WalnutiQ/wAlnut/issues/345) & realized `Q 0` made false assumptions about building AGI 2 help humanity in the 1st place. The goal changed 2 researching how 2 increase human 
intelligence faster than code based intelligence. The idea `Q 7` has reached is since AGI will not b limited by slow biological processes, it isn't possible 4 human intelligence 2 increase faster than code based intelligence in the long-term. Now `Q` is using 91 mental models 2 brainstorm alternative solutions 2 the AGI problem. If ur interested in thinking about this together e-mail `Q` ur CV @ emn1over12@gmail.com :)

~ `Q 246`

## Y & Goals
Between 2011 to 2016 `Q` was so focused on how 2 build AGI it was so easy for `Q` 2 have confirmation bias toward only potential positive effects of building AGI while a part of `Q` avoided the question:
  
`Q0: How do u control something that is smarter than all of humanity combined?`

The answer is u can't. `Q 230.35` now believes AGI shouldn't b built privately || publicly & instead 1 possible solution is 2 increase human intelligence with a privately built neural lace like [Neuralink](https://neuralink.com/) which u can read about [here](http://waitbutwhy.com/2017/04/neuralink.html). 

Today, many groups r trying 2 build AGI 2 help humanity. However, `Q` believes AGI shouldn't b built because:

1. Humans r the dominant species on Earth because of our intelligence.
2. If we make another species (code based AGI) smarter than us then there is no way for us 2 control it 
   because u can't control something that is more intelligent than all of humanity combined.
3. There is a very high chance that it will use humans 4 purposes we don't want. Just look @ how we treat species 
   that r less intelligent than us.
4. We can't stop the humans that r researching AGI so now the question is:

`Q1: How do we solve the AGI control problem?`  
Using a checklist of 91 mental models `Q` has brainstormed the following possible answers:

1. Increase human intelligence faster than AGI. 
   - `Problem:` AGI won't b limited by slow biological processes so `Q` doesn't think this is possible in the long-term. 
2. Give every1 who wants 1 a neural lace. 
   - `Problem:` Not sure if this is healthy for any human as it might cause insanity since we don't fully understand the brain yet. 
3. AGI development regulation.
   - `Problem:` `Q` doesn't think this is scalable since it will !b possible 2 monitor every AGI developer like it is possible 2 monitor every nuclear bomb developer. & as knowledge of how 2 build AGI increases more people with self-serving motives can create a AGI without understanding the consequences.
4. Figure out how 2 backwards time + universe travel ethically.
   - `Problem:` `Q` doesn't know any1 that will take `Q` seriously yet :) 
5. Something `Q` hasn't || can't even imagine yet. 

Using Occam's razor 2 is the possible answer with the least number of assumptions so now the questions becomes `Q2` & `Q3`:
  
`Q2: How do u create a safe neural lace 4 any1 who wants 1?`.

1. Use it 2 help mentally disabled. 
2. `Q` isn't sure giving a neural lace 2 a mentally "normal" person is healthy as our lack of full understanding of the brain may cause unexpected insanity in the wearer.
3. Privately research the best cyber security 2 b used 4 people with neural lace. 

`Q3: How do u fully understand the human brain without building 1 improved version of it in code?`

1. Non-Answer: In all other cases 2 truly understand a thing just rebuild 1 better version of it. However, in this case that means building an AGI. 

~ `Q 243`
